{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# gdown.download(url=\"https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/glove/vectors.zip\",output=\"vectors.zip\")\n",
    "# !unzip \"vectors.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "MAX_LENGTH = 0\n",
    "\n",
    "class Lang:\n",
    "   def __init__(self):\n",
    "       self.word2index = {}\n",
    "       self.word2count = {}\n",
    "       self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"PAD\"} #\n",
    "       self.n_words = 3  \n",
    "\n",
    "   def addSentence(self, sentence):\n",
    "       for word in sentence.split(' '):\n",
    "           self.addWord(word)\n",
    "\n",
    "   def addWord(self, word):\n",
    "       if word not in self.word2index:\n",
    "           self.word2index[word] = self.n_words\n",
    "           self.word2count[word] = 1\n",
    "           self.index2word[self.n_words] = word\n",
    "           self.n_words += 1\n",
    "       else:\n",
    "           self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(lang1,lang2):\n",
    "   global MAX_LENGTH\n",
    "   df = pd.read_csv('ferdousi.txt', header=None, names=['Beyt'])[2::]\n",
    "   d1 = df[0::2].values[:,0].tolist()\n",
    "   d2 = df[0::2].values[:,0].tolist()\n",
    "   df = pd.DataFrame({lang1:d1 , lang2:d2 })\n",
    "   source = Lang()\n",
    "   target = Lang()\n",
    "   pairs = []\n",
    "   sen1 = df[lang1]\n",
    "   sen2 = df[lang2]\n",
    "   \n",
    "   for i in range(len(df)):\n",
    "      if len(sen1[i].split(' ')) > MAX_LENGTH:\n",
    "         MAX_LENGTH = len(sen1[i].split(' '))\n",
    "   \n",
    "      source.addSentence(sen1[i])\n",
    "      target.addSentence(sen2[i])\n",
    "      pairs.append([sen1[i], sen2[i]])\n",
    "   \n",
    "   return source, target, pairs\n",
    "\n",
    "source, target, pairs = processing('M1', 'M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "   return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "   global MAX_LENGTH\n",
    "   global PAD_token\n",
    "   indexes = indexesFromSentence(lang, sentence)\n",
    "   pad_list=[PAD_token for i in range(MAX_LENGTH-len(indexes))]\n",
    "   indexes =  indexes  + pad_list\n",
    "   indexes.append(EOS_token)\n",
    "   return torch.tensor(indexes, dtype=torch.long,device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(input_lang, output_lang, pair):\n",
    "   input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "   target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "   return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "   def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers,GRU=False):\n",
    "       super(Encoder, self).__init__()\n",
    "      \n",
    "       self.input_dim = input_dim\n",
    "       self.embbed_dim = embbed_dim\n",
    "       self.hidden_dim = hidden_dim\n",
    "       self.num_layers = num_layers\n",
    "\n",
    "       self.embedding = nn.Embedding(input_dim, self.embbed_dim,padding_idx=2) \n",
    "       if GRU:\n",
    "        self.recurrent = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "       else:\n",
    "        self.recurrent = nn.LSTM(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "              \n",
    "   def forward(self, src):\n",
    "       embedded = self.embedding(src).view(1,1,-1)\n",
    "       outputs, hidden = self.recurrent(embedded)\n",
    "       return outputs, hidden\n",
    "   def initHidden(self):\n",
    "     return torch.zeros(1, 1, self.hidden_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "   def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers,GRU=False):\n",
    "       super(Decoder, self).__init__()\n",
    "\n",
    "       self.embbed_dim = embbed_dim\n",
    "       self.hidden_dim = hidden_dim\n",
    "       self.output_dim = output_dim\n",
    "       self.num_layers = num_layers\n",
    "\n",
    "       self.embedding = nn.Embedding(output_dim, self.embbed_dim ,padding_idx=2) # \n",
    "       \n",
    "       if GRU:\n",
    "        self.recurrent = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "       else :\n",
    "        self.recurrent=nn.LSTM(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "\n",
    "       self.out = nn.Linear(self.hidden_dim, output_dim)\n",
    "       self.softmax = nn.LogSoftmax(dim=1)\n",
    "      \n",
    "   def forward(self, input, hidden):\n",
    "\n",
    "       input = input.view(1, -1)\n",
    "       embedded = F.relu(self.embedding(input))\n",
    "       output, hidden = self.recurrent(embedded, hidden)       \n",
    "       prediction = self.softmax(self.out(output[0]))\n",
    "      \n",
    "       return prediction, hidden\n",
    "   def initHidden(self):\n",
    "      return torch.zeros(1, 1, self.hidden_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "   def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH,mode='GRU'):\n",
    "       super().__init__()\n",
    "      \n",
    "       self.encoder = encoder\n",
    "       self.decoder = decoder\n",
    "       self.device = device\n",
    "       self.mode = mode\n",
    "   def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "\n",
    "       input_length = source.size(0) \n",
    "       batch_size = target.shape[1] \n",
    "       target_length = target.shape[0]\n",
    "       vocab_size = self.decoder.output_dim\n",
    "      \n",
    "       outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "       for i in range(input_length):\n",
    "           encoder_output, encoder_hidden = self.encoder(source[i])\n",
    "       \n",
    "       if self.mode == \"GRU\":\n",
    "         decoder_hidden = encoder_hidden.to(device)\n",
    "       elif self.mode == \"LSTM\":\n",
    "         decoder_hidden = (encoder_hidden[0].to(device),encoder_hidden[1].to(device))\n",
    "       \n",
    "       decoder_input = torch.tensor([SOS_token], device=device) \n",
    "\n",
    "       for t in range(target_length):   \n",
    "           decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "           outputs[t] = decoder_output\n",
    "           teacher_force = random.random() < teacher_forcing_ratio\n",
    "           topv, topi = decoder_output.topk(1)\n",
    "           input = (target[t] if teacher_force else topi)\n",
    "           if(teacher_force == False and input.item() == EOS_token):\n",
    "               break\n",
    "\n",
    "       return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, input_lang, output_lang, sentences, MAX_LENGTH=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
    "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
    "        decoded_words = []\n",
    "        output = model(input_tensor, output_tensor)\n",
    "        for ot in range(output.size(0)):\n",
    "            topv, topi = output[ot].topk(1)\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
    "    return decoded_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "metric = datasets.load_metric('sacrebleu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence ['نکردند زیشان کسی آفرین', 'نکردند زیشان کسی آفرین']\n",
      "Input : 12687 Output : 12687\n"
     ]
    }
   ],
   "source": [
    "source, target, pairs = processing('M1', 'M2')\n",
    "print(f'random sentence {random.choice(pairs)}')\n",
    "print('Input : {} Output : {}'.format(source.n_words, target.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(source.n_words, 512, 256, 1,GRU=True)\n",
    "decoder = Decoder(target.n_words, 512, 256, 1,GRU=True)\n",
    "model = Seq2Seq(encoder, decoder, device,mode='GRU').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10004/100000 [02:53<29:28, 50.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :10000 , Loss : 3.544348538351059 , score :0.29426069483185535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20006/100000 [05:48<27:23, 48.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :20000 , Loss : 3.380070158545189 , score :0.5793217455610776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30002/100000 [08:42<24:09, 48.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :30000 , Loss : 3.349424096743259 , score :0.8643799903933321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40003/100000 [11:37<20:52, 47.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :40000 , Loss : 3.350461881113033 , score :1.1494347609575444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50004/100000 [14:32<18:20, 45.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :50000 , Loss : 3.3423789758364437 , score :1.434314864185007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60002/100000 [17:26<13:55, 47.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :60000 , Loss : 3.3451814335982015 , score :1.7184840942340827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70006/100000 [20:22<10:17, 48.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :70000 , Loss : 3.340851335668563 , score :2.002457300241479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80004/100000 [23:17<07:17, 45.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :80000 , Loss : 3.3400858798027175 , score :2.2864183024174864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90007/100000 [26:11<03:19, 49.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :90000 , Loss : 3.3364618187745285 , score :2.5696787283978413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [29:07<00:00, 57.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :100000 , Loss : 3.325283986695601 , score :2.853174840871889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_loss_iterations = 0\n",
    "final_score = 0\n",
    "training_pairs = [tensorsFromPair(source, target, random.choice(pairs))\n",
    "                    for i in range(100000)]\n",
    "\n",
    "for iter in tqdm(range(1, 100000+1)):\n",
    "    training_pair = training_pairs[iter - 1]\n",
    "    optimizer.zero_grad()\n",
    "    input_length = training_pair[0].size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(training_pair[0], training_pair[1],teacher_forcing_ratio)\n",
    "    num_iter = output.size(0)\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], training_pair[1][ot])\n",
    "    metric.add(predictions=output, references=training_pair[1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item() / num_iter\n",
    "    s  = metric.compute()\n",
    "    final_score += s['score']\n",
    "    total_loss_iterations += loss\n",
    "    if iter % 10000 == 0:\n",
    "        avarage_loss= total_loss_iterations / 10000\n",
    "        avg_score = final_score /10000\n",
    "        total_loss_iterations = 0\n",
    "        tqdm.write(f'iter :{iter} , Loss : {avarage_loss} , score :{avg_score}')\n",
    "        torch.save(model.state_dict(), f'GRU_Model.pt')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source ابر چشم او راست کن هر دو دست\n",
      "target ابر چشم او راست کن هر دو دست\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source تو خون سر بیگناهان مریز\n",
      "target تو خون سر بیگناهان مریز\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source برادر ندیدیم هرگز دو شاه\n",
      "target برادر ندیدیم هرگز دو شاه\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source چو هنگام برگشتن شاه بود\n",
      "target چو هنگام برگشتن شاه بود\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source چنان بد که ابلیس روزی پگاه\n",
      "target چنان بد که ابلیس روزی پگاه\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source ازان پس همه فیلسوفان شهر\n",
      "target ازان پس همه فیلسوفان شهر\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source بپرسید کز برتری کارها\n",
      "target بپرسید کز برتری کارها\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source بگرداندش سر ز یزدان پاک\n",
      "target بگرداندش سر ز یزدان پاک\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source چو جنبیدن شاه کردم درست\n",
      "target چو جنبیدن شاه کردم درست\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source چو بهرام بر شد ببالای تیغ\n",
      "target چو بهرام بر شد ببالای تیغ\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pair = random.choice(pairs)\n",
    "    print('source {}'.format(pair[0]))\n",
    "    print('target {}'.format(pair[1]))\n",
    "    output_words = evaluate(model, source, target, pair)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('predicted {}'.format(output_sentence))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence ['چومن زینهاری بود ننگ تو', 'چومن زینهاری بود ننگ تو']\n",
      "Input : 12687 Output : 12687\n"
     ]
    }
   ],
   "source": [
    "source, target, pairs = processing('M1', 'M2')\n",
    "print(f'random sentence {random.choice(pairs)}')\n",
    "print('Input : {} Output : {}'.format(source.n_words, target.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(source.n_words, 512, 256, num_layers=1,GRU=False)\n",
    "decoder = Decoder(target.n_words, 512, 256, num_layers=1,GRU=False)\n",
    "model = Seq2Seq(encoder, decoder, device,mode='LSTM').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10007/100000 [03:00<29:01, 51.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :10000 , Loss : 3.470179303646088 , score :0.29021072247338614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20004/100000 [06:01<28:12, 47.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :20000 , Loss : 3.4210155901749926 , score :0.5751614105561029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30005/100000 [09:02<26:32, 43.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :30000 , Loss : 3.473370235919937 , score :0.8587498145045047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40005/100000 [12:03<21:29, 46.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :40000 , Loss : 3.502995540046694 , score :1.1409924066143318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50002/100000 [15:03<19:01, 43.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :50000 , Loss : 3.5259281517346643 , score :1.4225587882500546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60001/100000 [18:04<14:50, 44.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :60000 , Loss : 3.55907597169876 , score :1.7040646270148914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70003/100000 [21:05<11:16, 44.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :70000 , Loss : 3.5835821776548897 , score :1.9856444379818203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80004/100000 [24:06<07:33, 44.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :80000 , Loss : 3.585838124910987 , score :2.2671662098443357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90003/100000 [27:07<03:36, 46.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :90000 , Loss : 3.567206091976192 , score :2.5487665648420297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [30:08<00:00, 55.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :100000 , Loss : 3.5860943871498216 , score :2.83020404350871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "total_loss_iterations = 0\n",
    "final_score = 0\n",
    "training_pairs = [tensorsFromPair(source, target, random.choice(pairs))\n",
    "                    for i in range(100000)]\n",
    "\n",
    "for iter in tqdm(range(1, 100000+1)):\n",
    "    training_pair = training_pairs[iter - 1]\n",
    "    optimizer.zero_grad()\n",
    "    input_length = training_pair[0].size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(training_pair[0], training_pair[1],teacher_forcing_ratio)\n",
    "    num_iter = output.size(0)\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], training_pair[1][ot])\n",
    "    metric.add(predictions=output, references=training_pair[1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item() / num_iter\n",
    "    s  = metric.compute()\n",
    "    final_score += s['score']\n",
    "    total_loss_iterations += loss\n",
    "    if iter % 10000 == 0:\n",
    "        avarage_loss = total_loss_iterations / 10000\n",
    "        avg_score = final_score /10000\n",
    "        total_loss_iterations = 0\n",
    "        tqdm.write(f'iter :{iter} , Loss : {avarage_loss} , score :{avg_score}')\n",
    "        torch.save(model.state_dict(), f'LSTM_Model.pt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source چو پیران چنان دید لشکر همه\n",
      "target چو پیران چنان دید لشکر همه\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source خور و خواب و آرام بر دشت و کوه\n",
      "target خور و خواب و آرام بر دشت و کوه\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source خردمند کز دور دریا بدید\n",
      "target خردمند کز دور دریا بدید\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source بدو گفت سهراب کز مرد پیر\n",
      "target بدو گفت سهراب کز مرد پیر\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source تهمتن چنین گفت با شهریار\n",
      "target تهمتن چنین گفت با شهریار\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source سپهدار ایران ز پشت سپاه\n",
      "target سپهدار ایران ز پشت سپاه\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source به جای زبونی و جای فریب\n",
      "target به جای زبونی و جای فریب\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source دگر کو بدرویش بر مهربان\n",
      "target دگر کو بدرویش بر مهربان\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source به پیلان گردون کش و گاومیش\n",
      "target به پیلان گردون کش و گاومیش\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
      "source چو بشنید ماهوی بیدادگر\n",
      "target چو بشنید ماهوی بیدادگر\n",
      "predicted چو گفت و و PAD PAD PAD PAD PAD PAD PAD <EOS>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pair = random.choice(pairs)\n",
    "    print('source {}'.format(pair[0]))\n",
    "    print('target {}'.format(pair[1]))\n",
    "    output_words = evaluate(model, source, target, pair)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('predicted {}'.format(output_sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
